{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bd8f1f-126f-498e-8a22-01af0b72c6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435cd838-f1d7-44f3-a704-4417c7f61adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = tf.keras.utils.get_file(\n",
    "    fname=\"cat.jpg\",\n",
    "    origin=\"https://img-datasets.s3.amazonaws.com/cat.jpg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254ea0e8-dd32-4a1d-a3c0-e31f7fc8a3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_array(img_path, target_size):\n",
    "    img = tf.keras.utils.load_img(\n",
    "        img_path, target_size=target_size)\n",
    "    x = tf.keras.utils.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e053461-3833-42f4-b8a0-ef56d8435f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = get_img_array(img_path, target_size=(180, 180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e9f8ce-0774-468d-b7e9-8006fdeec7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.applications.xception.Xception(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16584080-daac-467e-a6d6-327ad85dd569",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    if isinstance(layer, (tf.keras.layers.Conv2D, tf.keras.layers.SeparableConv2D)):\n",
    "        print(layer.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cae962-33c5-4522-8115-a9c357196aac",
   "metadata": {},
   "source": [
    "Because our model is a Functional API model, it is inspectable: we can query the output of one of its layers and reuse it in a new model. No need to copy the entire Xception code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9e4bec-5574-4662-a827-d8a59bf4500b",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = \"block3_sepconv1\"\n",
    "layer = model.get_layer(name=layer_name)\n",
    "feature_extractor = tf.keras.Model(inputs=model.input, outputs=layer.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e777711-f2bc-45fc-a289-edbad6df5a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = feature_extractor(\n",
    "    tf.keras.applications.xception.preprocess_input(img_tensor)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d92ce8-579e-41a6-917d-d0f8cf831b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aca67b2-555c-419b-8a4d-be4d9234f5e9",
   "metadata": {},
   "source": [
    "predict() loops over the data in batches (in fact, you can specify the batch size via predict(x,batch_size=64)\n",
    "\n",
    "This means that predict() calls can scale to very large arrays. Meanwhile, model(x) happens in-memory and doesnâ€™t scale. On the other hand, predict() is not differentiable: you cannot retrieve its gradient if you call it in a GradientTape scope.\n",
    "\n",
    "You should use model(x) when you need to retrieve the gradients of the model call, and you should use predict() if you just need the output value.A non-obvious trick to help the gradient descent process go smoothly is to normal- ize the gradient tensor by dividing it by its L2 norm (the square root of the average of the square of the values in the tensor). This ensures that the magnitude of the updates done to the input image is always within the same range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa259465-77b4-473f-90c2-00055ef35449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(image, filter_index):\n",
    "    activation = feature_extractor(image)\n",
    "    filter_activation = activation[:, 2:-2, 2:-2, filter_index]\n",
    "    return tf.reduce_mean(filter_activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a416821e-c3b9-473d-aa27-9cf01f93e4e6",
   "metadata": {},
   "source": [
    "A non-obvious trick to help the gradient descent process go smoothly is to normal- ize the gradient tensor by dividing it by its L2 norm (the square root of the average of the square of the values in the tensor). This ensures that the magnitude of the updates done to the input image is always within the same range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3aae19-df27-4cbb-a10b-02c0d60eefea",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def gradient_ascent_step(image, filter_index, learning_rate):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(image)\n",
    "        loss = compute_loss(image, filter_index)\n",
    "    grads = tape.gradient(loss, image)\n",
    "    grads = tf.math.l2_normalize(grads)\n",
    "    image += learning_rate * grads\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a7e97f-aa1f-4b8f-8b0e-f5964f6bfe9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 200\n",
    "img_height = 200\n",
    "\n",
    "def generate_filter_pattern(filter_index):\n",
    "    iterations = 30\n",
    "    learning_rate = 10.\n",
    "    image = tf.random.uniform(\n",
    "        minval=0.4,\n",
    "        maxval=0.6,\n",
    "        shape=(1, img_width, img_height, 3))\n",
    "    for i in range(iterations):\n",
    "        image = gradient_ascent_step(image, filter_index, learning_rate)\n",
    "    return image[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2a160d-2768-45a5-a72f-d46ce0026422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprocess_image(image):\n",
    "    image -= image.mean()\n",
    "    image /= image.std()\n",
    "    image *= 64\n",
    "    image += 128\n",
    "    image = np.clip(image, 0, 255).astype(\"uint8\")\n",
    "    image = image[25:-25, 25:-25, :]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e343cc21-bb26-4065-a984-4e12d903d2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis(\"off\")\n",
    "plt.imshow(deprocess_image(generate_filter_pattern(filter_index=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad11ff59-c13f-492c-9dd4-d0587a610771",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = []\n",
    "for filter_index in range(64):\n",
    "    print(f\"Processing filter {filter_index}\")\n",
    "    image = deprocess_image(\n",
    "        generate_filter_pattern(filter_index)\n",
    "    )\n",
    "    all_images.append(image)\n",
    "\n",
    "margin = 5\n",
    "n = 8\n",
    "cropped_width = img_width - 25 * 2\n",
    "cropped_height = img_height - 25 * 2\n",
    "width = n * cropped_width + (n - 1) * margin\n",
    "height = n * cropped_height + (n - 1) * margin\n",
    "stitched_filters = np.zeros((width, height, 3))\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        image = all_images[i * n + j]\n",
    "        stitched_filters[\n",
    "            (cropped_width + margin) * i : (cropped_width + margin) * i + cropped_width,\n",
    "            (cropped_height + margin) * j : (cropped_height + margin) * j\n",
    "            + cropped_height,\n",
    "            :,\n",
    "        ] = image\n",
    "\n",
    "tf.keras.utils.save_img(\n",
    "    f\"filters_for_layer_{layer_name}.png\", stitched_filters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
