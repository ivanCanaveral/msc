{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EU4w3N_MTRXo"
   },
   "source": [
    "# Ejercicio práctico - Tema 2: Modelo de Espacio Vectorial\n",
    "\n",
    "**Alumno**: Iván Cañaveral Sánchez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wq2dGJG0TX42"
   },
   "source": [
    "El objetivo de este ejercicio práctico es el estudio de la representación dentro del\n",
    "modelo de espacio vectorial. Para ello vamos a generar representaciones dentro de este\n",
    "modelo con diferentes funciones de pesado y evaluarlas dentro de un problema de\n",
    "clustering de documentos.\n",
    "\n",
    "Como objetivo principal, vamos a generar represeantaciones vectoriales empleando estas tres funciones de pesado:\n",
    "* TF\n",
    "* TF-IDF\n",
    "* Binary\n",
    "\n",
    "Una vez obtenidos los vectores de representación se ejecutará un algoritmo de\n",
    "clustering y se compararán los resultados obtenidos, tratándolos de relacionar con la\n",
    "función de pesado aplicada en cada caso.\n",
    "\n",
    "A continuación analizamos IDF en este problema,\n",
    "calculando la frecuencia de documentos de cada término, y ver si existen\n",
    "términos que caractericen algún grupo o si en caso contrario, la penalización del factor IDF a aquellos\n",
    "términos presentes en un número elevado (o no tan elevado) de documentos es una\n",
    "estimación correcta para esta tarea.\n",
    "\n",
    "Tras esto, evaluaremos el impacto que tiene la aplicación de LSI en este problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ymHUM9v2Ta5j"
   },
   "source": [
    "## Librerías y constantes\n",
    "\n",
    "En este apartado importamos las librerías necesarias para el desarrollo del ejercicio práctico. También fijamos algunos parámetros de la vectorización com variables globales, para que queden fijadas apra todas las representaciones.\n",
    "\n",
    "Las principales librerías que utilizaremos serán:\n",
    "* `numpy`\n",
    "* `pandas`\n",
    "* `seaborn`\n",
    "* `sklearn`\n",
    "\n",
    "Como algoritmo de clústering, elegiremos `KMeans` por su simplicidad.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xp93xOVKhU2y"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qKm3g_yErQSk"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fk0xxFyTxhX2",
    "outputId": "f428d01f-4266-41f9-c5c6-828833c1f2a4"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "sns.set(rc={'figure.figsize':(11,8)})\n",
    "sns.color_palette(\"crest\", as_cmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5cpout0jhEct"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zXKMTfE-hFkG"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H7OD2KWfm-U4"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RAR0mg29hP4x"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "from sklearn import metrics\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yFx8C8lSg-Oe"
   },
   "outputs": [],
   "source": [
    "MAX_DF = 1.0\n",
    "MIN_DF = 10\n",
    "MAX_FEATURES = 10_000\n",
    "SEED = 73"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fyva64xSZoNn"
   },
   "source": [
    "## Carga del detaset\n",
    "\n",
    "\n",
    "Vamos  acargar un dataset público conocido como `20newsgroups_dataset`, que consiste en unos 18.000 textos repartidos en varias categorías. Elegimos este conjunto de datos dadas las facilidades que las principales librerías de ML ofrecen para su descarga. Está incluído en las principales librerías, entre ellas `sklearn` o `tensorflow`.\n",
    "\n",
    "Para acotar el ámbito de la práctica, vamos e seleccionar las siguientes categorías:\n",
    "\n",
    "```\n",
    "    \"alt.atheism\",\n",
    "    \"talk.religion.misc\",\n",
    "    \"comp.graphics\",\n",
    "    \"sci.space\",\n",
    "    \"rec.autos\",\n",
    "    \"rec.motorcycles\"\n",
    "```\n",
    "\n",
    "En el dataset podemos encontrar otros tipos de meta información como `\"headers\"`, `\"footers\"` o `\"quotes\"` que por el momento vamos a descartar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JDVpFie6ZoNo",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "87e5f746-1fd0-4e1b-b84f-842c0e6c715d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = [\n",
    "    \"alt.atheism\",\n",
    "    \"talk.religion.misc\",\n",
    "    \"comp.graphics\",\n",
    "    \"sci.space\",\n",
    "    \"rec.autos\",\n",
    "    \"rec.motorcycles\"\n",
    "]\n",
    "\n",
    "dataset = fetch_20newsgroups(\n",
    "    remove=(\"headers\", \"footers\", \"quotes\"),\n",
    "    subset=\"all\",\n",
    "    categories=categories,\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "labels = dataset.target\n",
    "unique_labels, category_sizes = np.unique(labels, return_counts=True)\n",
    "true_k = unique_labels.shape[0]\n",
    "\n",
    "print(f\"{len(dataset.data)} documents - {true_k} categories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hT58Ulk2c20U"
   },
   "source": [
    "Vamos a explorar brevemente la información del conjunto de datos. Aquí tenemos uno de los textos del dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "Iwj8bEEYbLo4",
    "outputId": "73bea2c3-0a7e-48c0-e7d6-23c20f1e7e83"
   },
   "outputs": [],
   "source": [
    "dataset[\"data\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "id_s5UtmdBb3"
   },
   "source": [
    "Y a continuación podemos ver las etiquetas de los datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rOHyV950bT6P",
    "outputId": "fcd1cc34-8e98-4cfa-d7a9-36d7ac8af01d"
   },
   "outputs": [],
   "source": [
    "dataset[\"target\"][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moIv6OJIg7Ry"
   },
   "source": [
    "## Vectorizadores\n",
    "\n",
    "Vamos a crear a continuación los objetos que vamos a utilizar para generar las representaciones. En todos ellos fijaremos los parámetros `MAX_DF`, `MIN_DF` y `MAX_FEATURES`.\n",
    "\n",
    "Vamos a apoyarnos en las clases `CountVectorizer` y `TfidfVectorizer`, que permiten generar las representaciones esperadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i8WXuuVnhNb7"
   },
   "outputs": [],
   "source": [
    "# con el parámetro binary=False, la representación ofrecerá el número de \n",
    "# veces que aparece una palabra en un texto\n",
    "tf_vectorizer = CountVectorizer(\n",
    "    max_df=MAX_DF,\n",
    "    min_df=MIN_DF,\n",
    "    max_features=MAX_FEATURES,\n",
    "    binary=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uR2Z4wcnhvZc"
   },
   "outputs": [],
   "source": [
    "tf_idf_vectorizer = TfidfVectorizer(\n",
    "    max_df=MAX_DF,\n",
    "    min_df=MIN_DF,\n",
    "    max_features=MAX_FEATURES,\n",
    "    use_idf=True, # aplicamos idf\n",
    "    smooth_idf=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XkNSdJ0FhwjV"
   },
   "outputs": [],
   "source": [
    "# con el parámetro binary=True, la representación ofrecerá variables \n",
    "# binarias que indican si aparece una palabra en un texto\n",
    "binary_vectorizer = CountVectorizer(\n",
    "    max_df=MAX_DF,\n",
    "    min_df=MIN_DF,\n",
    "    max_features=MAX_FEATURES,\n",
    "    binary=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rr41cP5sofMJ"
   },
   "source": [
    "### Ajuste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HxUbP45FgB5p"
   },
   "source": [
    "Ahora vamos a ajustar estos vectorizadores y a generar las representaciones.\n",
    "\n",
    "Vamos a generar un diccionario para guardar estos objetos (`vectorizers`), y otro para las representaciones (`vectors`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gAheCZxeiS_r"
   },
   "outputs": [],
   "source": [
    "vectorizers = {\n",
    "    'tf': tf_vectorizer,\n",
    "    'tf_idf': tf_idf_vectorizer,\n",
    "    'binary': binary_vectorizer\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HQMIRXXdix6k"
   },
   "outputs": [],
   "source": [
    "vectors = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BTrqHGCciVCK",
    "outputId": "cf8603c9-4f83-4eb2-bdbf-be76e8fd8e38"
   },
   "outputs": [],
   "source": [
    "for vectorizer_name, vectorizer in vectorizers.items():\n",
    "  print(f'fitting {vectorizer_name} vectorizer ...')\n",
    "  vectors[vectorizer_name] = vectorizer.fit_transform(dataset.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FKDq6NhkgjtS"
   },
   "source": [
    "Comprobamos cuántos textos y variables se han registrado en cada representación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0halFz7-i9n4",
    "outputId": "6e8d64d7-7de8-4b56-ccc6-af25971d406d"
   },
   "outputs": [],
   "source": [
    "for vectorizer_name, X in vectors.items():\n",
    "  print(f\"{vectorizer_name}: n_samples: {X.shape[0]}, n_features: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0dk-nCMg62x"
   },
   "source": [
    "Las matrices de estas representaciones sulen ser poco densas. Para intentar metrizar esto de alguna manera, vamos a intentar medir el porcentaje de elementos que guardan estas matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d7YwbdzemMB0",
    "outputId": "c5caf7cf-59ff-4e35-cf30-151bbd51b5b7"
   },
   "outputs": [],
   "source": [
    "for vectorizer_name, X in vectors.items():\n",
    "  print(f\"{vectorizer_name}: {X.nnz / np.prod(X.shape):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1hwryejrNO7W"
   },
   "source": [
    "Finalmente vamos a revisar las representaciones generadas, entendiendo cómo son los valores distintos de cero. Observamos que en el caso de `tf` son enteros, `binary` valores binarios, y `tf_idf` son números no enteros, com cabía esperar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b-E5TeMWOR2l",
    "outputId": "674a6950-65a7-4c1f-b992-9b8d13fdb8ab"
   },
   "outputs": [],
   "source": [
    "vectors['tf'][vectors['tf'].nonzero()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nnBRtFWcNS6n",
    "outputId": "eef5fc0d-88b0-467e-9afd-514a38abe12a"
   },
   "outputs": [],
   "source": [
    "vectors['binary'][vectors['binary'].nonzero()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JUHBTSEOOBI4",
    "outputId": "b4824838-8ee9-4ac0-e7ef-1b1e388eb22e"
   },
   "outputs": [],
   "source": [
    "vectors['tf_idf'][vectors['tf_idf'].nonzero()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0_EQtmThcqt"
   },
   "source": [
    "### Cálculo de valores idf\n",
    "\n",
    "Dado que uno de los elementos que revisaremos en esta práctica son los valores de idf, vamos a calcularlos y a explorarlos brevemente para ganar intuición sobre la pregunta a responder en esta práctica sobre su impacto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vKYYEhamjT32"
   },
   "outputs": [],
   "source": [
    "idf_values = {k:v for k, v in zip(vectorizers['tf_idf'].get_feature_names_out(), vectorizers['tf_idf'].idf_)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xD1hZldh1lc"
   },
   "source": [
    "Revisemos a continuación los elementos con menor valor de idf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E832OhDljoxH",
    "outputId": "9596d902-d6a3-472c-df5c-171f8e09fe83"
   },
   "outputs": [],
   "source": [
    "sorted_idf_values = dict(sorted(idf_values.items(), key=lambda item: item[1], reverse=False))\n",
    "for word, value in list(sorted_idf_values.items())[:10]:\n",
    "  print(f\"Word: {word} \\t Value: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X3ytT08hieSM"
   },
   "source": [
    "Como podemos observar, las palabras con menos valor son principalmente palabras de baja carga semántica (stopwords en su mayoría)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Aq4Xx88ipLw"
   },
   "source": [
    "Revisemos ahora con mayores valores de `idf`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ygfTuNy6jbk0",
    "outputId": "e1c0bf68-934f-4223-ec0b-261af9275937"
   },
   "outputs": [],
   "source": [
    "sorted_idf_values = dict(sorted(idf_values.items(), key=lambda item: item[1], reverse=True))\n",
    "for word, value in list(sorted_idf_values.items())[50:60]:\n",
    "  print(f\"Word: {word} \\t Value: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KjCHVv25i6MB"
   },
   "source": [
    "Muchas de ellas parecen palabras con una mayor carga semántica, y que pueden tener un mayor peso en la generación del clústering.\n",
    "\n",
    "Revisaremos su impacto en las próximas secciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RhGRyHoZgRlx"
   },
   "source": [
    "## Algoritmo clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXv6zj4ZlY-O"
   },
   "source": [
    "Como algoritmo de clústering hemos elegido uno de los más sencillos, por simplicidad y para poder centrarnos en la representación.\n",
    "\n",
    "Sin embargo, debemos tener en cuenta un punto que, si bien no es específico de `KMeans`, debemos tener en mente para poder interpretar correctamente los resultados.\n",
    "\n",
    "Cuando trabajamos con dimensionalidades altas `k-means` puede inicializar centroides en puntos de datos extremadamente aislados. Esos puntos de datos pueden seguir siendo sus propios centroides todo el tiempo.\n",
    "\n",
    "El siguiente fragmento código ilustra cómo el fenómeno anterior a veces puede conducir a clusters muy desequilibrados, dependiendo de la inicialización aleatoria:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IEeTCBpngUre",
    "outputId": "84d762e6-5541-4b51-9e36-714970eead0e"
   },
   "outputs": [],
   "source": [
    "for seed in range(5):\n",
    "    kmeans = KMeans(\n",
    "        n_clusters=true_k,\n",
    "        max_iter=100,\n",
    "        n_init=1,\n",
    "        random_state=seed,\n",
    "    ).fit(vectors['tf_idf'])\n",
    "    cluster_ids, cluster_sizes = np.unique(kmeans.labels_, return_counts=True)\n",
    "    print(f\"Number of elements asigned to each cluster: {cluster_sizes}\")\n",
    "print()\n",
    "print(\n",
    "    \"True number of documents in each category according to the class labels: \"\n",
    "    f\"{category_sizes}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u8Wb0Cx7lKba"
   },
   "source": [
    "Vemos como cada categoría tiene entre 600 y 1000 textos, y sin embargo es frecuente encontrar clúster con entre 10 y 50 elementos. Para intentar regular esto, vamos a utilizar el parámetro `n_init`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x6qL1Zqxlo3w",
    "outputId": "7a9097c7-5d49-4a46-fd0a-af638ed4b607"
   },
   "outputs": [],
   "source": [
    "for seed in range(5):\n",
    "    kmeans = KMeans(\n",
    "        n_clusters=true_k,\n",
    "        max_iter=100,\n",
    "        n_init=20,\n",
    "        random_state=seed,\n",
    "    ).fit(vectors['tf_idf'])\n",
    "    cluster_ids, cluster_sizes = np.unique(kmeans.labels_, return_counts=True)\n",
    "    print(f\"Number of elements asigned to each cluster: {cluster_sizes}\")\n",
    "print()\n",
    "print(\n",
    "    \"True number of documents in each category according to the class labels: \"\n",
    "    f\"{category_sizes}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X3fe6eh3lH1G"
   },
   "source": [
    "Vemos que ahora el número de elementos de los diferentes grupos son mucho más estables, aunque esto tiene cierto impacto en los tiempos de ejecución."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pt9OG_4JpXy-"
   },
   "source": [
    "### Definición de la clase\n",
    "\n",
    "Por lo tanto, vamos a fijar los mismos parámetros del algoritmos de clústering para todas las funciones de pesado, y entre los parámetros vamos a utilizar un `n_init` de 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UesZU2fOpTGR"
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(\n",
    "    n_clusters=true_k,\n",
    "    max_iter=100,\n",
    "    n_init=20,\n",
    "    random_state=SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zrWe57PxliGx"
   },
   "source": [
    "## Evaluación de resultados\n",
    "\n",
    "Vamos a definir cómo vamos a medir los resultados del clústering, el impacto de las diferentes funciones de pesado y com hacer seguimiento de los resultados.\n",
    "\n",
    "Dado que disponemos de etiquetas de clase para este conjunto de datos específico, es posible utilizar métricas de evaluación que aprovechen esta información \"supervisada\" para cuantificar la calidad de los clusters resultantes.\n",
    "\n",
    "Ejemplos de estas métricas son los siguientes:\n",
    "\n",
    "- **Homogeneidad**, que cuantifica en qué medida los clusters contienen sólo miembros de una única clase.\n",
    "\n",
    "- **Exhaustividad**, que cuantifica cuántos miembros de una clase determinada están asignados a los mismos clusters.\n",
    "\n",
    "- La **medida V**, que es la media armónica de la exhaustividad y la homogeneidad.\n",
    "\n",
    "- **Índice de Rand**, que mide la frecuencia con que los pares de puntos de datos se agrupan de forma coherente según el resultado del algoritmo de y la asignación de clase real.\n",
    "\n",
    "- **Índice de Rand ajustado**, un índice de Rand ajustado al azar de forma que la asignación aleatoria de clusters tiene un índice esperado de 0,0.\n",
    "\n",
    "Si no se conocen las etiquetas, la evaluación sólo puede realizarse con los propios resultados del modelo de agrupamiento. En ese caso, el [coeficiente de silueta](https://en.wikipedia.org/wiki/Silhouette_(clustering)) resulta muy útil.\n",
    "\n",
    "Todas estas métricas de evaluación de la agrupación tienen un valor máximo de 1,0 (para un resultado de agrupación perfecto). Debermos tener en cuenta que las etiquetas de clase pueden no reflejar con exactitud los temas de los documentos y, por tanto, las métricas que utilizan etiquetas pueden no ser un sistema de evaluación óptimo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ixPafodopbI"
   },
   "source": [
    "Vamos a ir guardando los resultados de las evaluaciones en las siguientes variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0zqoKo8sluJM"
   },
   "outputs": [],
   "source": [
    "evaluations = []\n",
    "evaluations_std = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o7Jaenbno4fY"
   },
   "source": [
    "A continuación vamos a escribir una función que nos permita hacer una evaluación rápida del problema en términos de las métricas definidas. Para cada experimento utilizaremos por defecto 5 repeticiones del clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_45jF-ugo3BM"
   },
   "outputs": [],
   "source": [
    "def quick_eval(km, X, n_runs=5, threshold=0.0):\n",
    "    scores = defaultdict(list)\n",
    "    for seed in range(n_runs):\n",
    "        km.set_params(random_state=seed)\n",
    "        t0 = time()\n",
    "        km.fit(X)\n",
    "        scores[\"Homogeneity\"].append(metrics.homogeneity_score(labels, km.labels_))\n",
    "        scores[\"Completeness\"].append(metrics.completeness_score(labels, km.labels_))\n",
    "        scores[\"V-measure\"].append(metrics.v_measure_score(labels, km.labels_))\n",
    "        scores[\"Adjusted Rand-Index\"].append(\n",
    "            metrics.adjusted_rand_score(labels, km.labels_)\n",
    "        )\n",
    "    avg_scores = []\n",
    "    for score_name, score_values in scores.items():\n",
    "        mean_score = np.mean(score_values)\n",
    "        print(f\"{score_name}: {mean_score:.3f}\")\n",
    "        avg_scores.append(\n",
    "            {\n",
    "                'score_name': score_name,\n",
    "                'score': mean_score,\n",
    "                'threshold': threshold\n",
    "            }\n",
    "        )\n",
    "    return avg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZCSmwmJnpA_E",
    "outputId": "2f502447-aeea-452a-d19c-d6586d4496fe"
   },
   "outputs": [],
   "source": [
    "_ = quick_eval(kmeans, vectors['tf_idf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8zJbr6AdpAL1"
   },
   "source": [
    "Adicionalmente vamos a definir una función similar, pero que nos permita ir haciendo un seguimiento de los resultados para hacer una comparativa de resultados incluyendo los más relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iEzaMJquZoNq",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def track_experiment(km, X, name=None, n_runs=5):\n",
    "    name = km.__class__.__name__ if name is None else name\n",
    "\n",
    "    train_times = []\n",
    "    scores = defaultdict(list)\n",
    "    for seed in range(n_runs):\n",
    "        km.set_params(random_state=seed)\n",
    "        t0 = time()\n",
    "        km.fit(X)\n",
    "        train_times.append(time() - t0)\n",
    "        scores[\"Homogeneity\"].append(metrics.homogeneity_score(labels, km.labels_))\n",
    "        scores[\"Completeness\"].append(metrics.completeness_score(labels, km.labels_))\n",
    "        scores[\"V-measure\"].append(metrics.v_measure_score(labels, km.labels_))\n",
    "        scores[\"Adjusted Rand-Index\"].append(\n",
    "            metrics.adjusted_rand_score(labels, km.labels_)\n",
    "        )\n",
    "        scores[\"Silhouette Coefficient\"].append(\n",
    "            metrics.silhouette_score(X, km.labels_, sample_size=2000)\n",
    "        )\n",
    "    train_times = np.asarray(train_times)\n",
    "\n",
    "    print(f\"clustering done in {train_times.mean():.2f} ± {train_times.std():.2f} s \")\n",
    "    evaluation = {\n",
    "        \"estimator\": name,\n",
    "        \"train_time\": train_times.mean(),\n",
    "    }\n",
    "    evaluation_std = {\n",
    "        \"estimator\": name,\n",
    "        \"train_time\": train_times.std(),\n",
    "    }\n",
    "    for score_name, score_values in scores.items():\n",
    "        mean_score, std_score = np.mean(score_values), np.std(score_values)\n",
    "        print(f\"{score_name}: {mean_score:.3f} ± {std_score:.3f}\")\n",
    "        evaluation[score_name] = mean_score\n",
    "        evaluation_std[score_name] = std_score\n",
    "    evaluations.append(evaluation)\n",
    "    evaluations_std.append(evaluation_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CtP3BrQ2ukv0"
   },
   "source": [
    "Finalmente, vamos a generar una función para mostras las palabras más importantes de cada clúster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ufWFEhWVuitZ"
   },
   "outputs": [],
   "source": [
    "def get_top_words(centroids, vectorizer):\n",
    "    order_centroids = centroids.argsort()[:, ::-1]\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "    for i in range(true_k):\n",
    "        print(f\"Cluster {i}: \", end=\"\")\n",
    "        for ind in order_centroids[i, :10]:\n",
    "            print(f\"{terms[ind]} \", end=\"\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YOz0BazyrsX_"
   },
   "source": [
    "### Primeros resutados\n",
    "\n",
    "Vamos a registrar las métricas de las representaciones con las tres funciones de pesado definidas, así como a mostrar las palabras más relevantes en cada caso para poder analizarlas a posteriori."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVLl63PJu-DR"
   },
   "source": [
    "#### Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iQjO5JserP-g",
    "outputId": "ffcd3c52-d489-4230-b398-9d156a3be689"
   },
   "outputs": [],
   "source": [
    "track_experiment(kmeans, vectors['binary'], name=\"KMeans\\non binary vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tzl5JvUDvGte",
    "outputId": "3cb0d63c-360d-428f-f724-b071ab27d38c"
   },
   "outputs": [],
   "source": [
    "centroids = kmeans.cluster_centers_\n",
    "get_top_words(centroids, vectorizers['binary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIAdwZwwQhzL"
   },
   "source": [
    "Vemos como las métricas son bastante bajas, y como al explorar las palabras más relevantes nos encontramos con una gran presencia de stopwords y otras palabras con baja carga semántica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ycU39-P7vNMt"
   },
   "source": [
    "#### TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zEY-lu6eQ-yf",
    "outputId": "4d2fda26-81db-4ad0-c626-1686f29c1bcb"
   },
   "outputs": [],
   "source": [
    "track_experiment(kmeans, vectors['tf'], name=\"KMeans\\non tf vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZgJVXU0hvQt5",
    "outputId": "6ad41ff7-adc6-4eaa-fc67-42dce76cf622"
   },
   "outputs": [],
   "source": [
    "centroids = kmeans.cluster_centers_\n",
    "get_top_words(centroids, vectorizers['tf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPa1kbLPQ-jp"
   },
   "source": [
    "En este caso, las métricas siguen siendo bajas, pero podemos observar como la selección de palabras relevantes es incluso menos significativa que en el caso anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7qOrN8fvSDX"
   },
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JZR6BY7GoJYi",
    "outputId": "64cb5403-a427-455a-c1e5-4e36fa958894"
   },
   "outputs": [],
   "source": [
    "track_experiment(kmeans, vectors['tf_idf'], name=\"KMeans\\non tf-idf vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZIHJfoAktZxp",
    "outputId": "2e287545-b399-4990-e893-1d4b3041bd2b"
   },
   "outputs": [],
   "source": [
    "centroids = kmeans.cluster_centers_\n",
    "get_top_words(centroids, vectorizers['tf_idf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jUd_YdhRRggv"
   },
   "source": [
    "En el caso de `tf_idf` observamos un claro incremento en las métricas, lo que sugiere un potencial impacto positivo de los términos de `idf`, aunque la exploración de los términos más relevantes sigue mostrando que el clústering no está siendo tan efectivo como debería ser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KW9V6Hv0xu5O"
   },
   "source": [
    "#### Comparativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMYBjh2Xr7gr"
   },
   "source": [
    "Como podemos observar, las métricas de la función de pesado que incluye `idf` son son considerablementes mejores. Esto, unido a la exploración que habíamos hecho de los valores de `idf` de los diferentes términos, empiezan a generarnos una intuición clara sobre el impacto que tiene en las representaciones, reduciendo el número de variables superfluas de la representación.\n",
    "\n",
    "Prestando atención a las palabras más relevantes en cada caso, podemos ver que en todos los casos tenemos multitud de palabras con muy poca carga semántica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEZaWKE2tmis"
   },
   "source": [
    "Vamos a generar una función que nos ayude a visualizar los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "39WN_j44szNR"
   },
   "outputs": [],
   "source": [
    "def plot_experiment(evaluations, evaluations_std, size=(6, 10)):\n",
    "    pd.DataFrame(evaluations[::-1]).set_index(\"estimator\")\n",
    "    fig, ax = plt.subplots(figsize=size, sharey=True)\n",
    "\n",
    "    df = pd.DataFrame(evaluations[::-1]).set_index(\"estimator\")\n",
    "    df_std = pd.DataFrame(evaluations_std[::-1]).set_index(\"estimator\")\n",
    "\n",
    "    df.drop(\n",
    "        [\"train_time\"],\n",
    "        axis=\"columns\",\n",
    "    ).plot.barh(ax=ax, xerr=df_std)\n",
    "    ax.set_xlabel(\"Clustering scores\")\n",
    "    ax.set_ylabel(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "id": "oC4Q89datbBk",
    "outputId": "e76b0d10-90fc-4186-c870-d34798b330ee"
   },
   "outputs": [],
   "source": [
    "plot_experiment(evaluations, evaluations_std, size=(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQT2wb3at4aF"
   },
   "source": [
    "Como vemos, las métricas de las funciones de pesado `tf`y `binary`, indican que está siendo muy complicado llevar a cabo una separación clara de los clusters. De hecho, el valor tan elevado de Homogeneidad que presentan los resultados de la función `tf` indican que probablemente exista un gran clúster que contiene muchos de los textos. \n",
    "\n",
    "Pare entender esto en detalle, y por qué la homogeneidad es alta, vamos a llevar a cabo un pequeño test. Vamos a ajustar de nuevo un conjunto de clusters con la función de de pesado `tf` por ejemplo, y veremos cuántas etiquetas se asignan a cada categoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qX3pAOjUuWZH"
   },
   "outputs": [],
   "source": [
    "test_kmeans = KMeans(\n",
    "    n_clusters=true_k,\n",
    "    max_iter=100,\n",
    "    n_init=20,\n",
    "    random_state=SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q1mwdXPZuWFF"
   },
   "outputs": [],
   "source": [
    "_ = test_kmeans.fit_transform(vectors['tf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dDidrw_iull6",
    "outputId": "400dcfad-b14b-40c9-ceef-4ea1cd2c1995"
   },
   "outputs": [],
   "source": [
    "Counter(test_kmeans.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uCLFFwRovGkG"
   },
   "source": [
    "Como podemos ver, casi todos los textos están dentro del mismo conjunto, y luego hay conjuntos con muy pocos elementos de una misma categorías, que elevan la homogoeneidad del mismo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4qDi00KLTU_c"
   },
   "source": [
    "En la siguiente celda de código, y adelantándonos a resultados posteriores, podemos ver cómo con una reducción agresiva de la dimensionalidad perdemos poca información. Retomaremos esta línea más tarde. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IvgFAW2U7HBH",
    "outputId": "dfc9028a-df28-4bf1-b866-9357b557d205"
   },
   "outputs": [],
   "source": [
    "lsa = make_pipeline(TruncatedSVD(n_components=100), Normalizer(copy=False))\n",
    "t0 = time()\n",
    "X_lsa = lsa.fit_transform(vectors['tf'])\n",
    "explained_variance = lsa[0].explained_variance_ratio_.sum()\n",
    "\n",
    "print(f\"LSA done in {time() - t0:.3f} s\")\n",
    "print(f\"Explained variance of the SVD step: {explained_variance * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_DppTgxrj0j"
   },
   "source": [
    "## Impacto de valores IDF\n",
    "\n",
    "Vamos a ver ahora el impacto de los valores de `idf` a la hora de seleccionar palabras más relevantes. Para ello, vamos a estudiar qué ocurre si eliminamos algunos términos en función de sus pesos de IDF.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B1R5F39trodm",
    "outputId": "fbdc053b-9feb-477f-8904-14538b20906e"
   },
   "outputs": [],
   "source": [
    "idf_values = dict(sorted(idf_values.items(), key=lambda item: item[1], reverse=False))\n",
    "len(idf_values.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWLjHH0zrmIO"
   },
   "source": [
    "### Restricción de valores bajos de idf\n",
    "\n",
    "Cómo ya habíamso visto, las palabras con valores bajso son extremadamente comunes y no sirven en general para poder diferenciar clústers ni aportan en la definición de un modelo de espacio vectorial.\n",
    "\n",
    "Vamos a ver cómo impacta la eliminación de las palabras de peso de idf bajo. Vamos a probar con diferentes límites y extraeremos las métricas de los clusters asociados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ckJlvCCLrtxE",
    "outputId": "7c3f4cd1-5835-41de-8510-d2570aecaff0"
   },
   "outputs": [],
   "source": [
    "vocab_sizes = []\n",
    "experiment_scores = []\n",
    "for threshold in np.arange(1,7,0.5).tolist():\n",
    "    vocabulary = [word for word, idf_value in idf_values.items() if idf_value > threshold]\n",
    "    print(f\"\\n Threshold: {threshold}, vocab size {len(vocabulary)} \\n\", \"-\"*10)\n",
    "    vocab_sizes.append(\n",
    "        {\n",
    "            'threshold': threshold,\n",
    "            'vocab_size': len(vocabulary)\n",
    "        }\n",
    "    )\n",
    "    tf_idf_vectorizer = TfidfVectorizer(\n",
    "        max_df=MAX_DF,\n",
    "        min_df=MIN_DF,\n",
    "        vocabulary=vocabulary,\n",
    "        use_idf=True, #if False => tf_vectorize\n",
    "        smooth_idf=1\n",
    "    )\n",
    "    X_tfidf = tf_idf_vectorizer.fit_transform(dataset.data)\n",
    "    scores = quick_eval(kmeans, X_tfidf, threshold=threshold)\n",
    "    experiment_scores += scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCh3rIyojzod"
   },
   "source": [
    "Vamos a visualizar los resultados, para intentar encontrar un punto de corte óptimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dECsStUYsSZe"
   },
   "outputs": [],
   "source": [
    "experiment_scores = pd.DataFrame(experiment_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "crFiV_6uT3L7"
   },
   "source": [
    "En la siguiente gráfica podemos visualizar los resultados del experimento previo, y ver cómo varían las métricas del clústering, en función del filtrado que se hace en función de los pesos de `idf`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "id": "b3sE3fePyNz0",
    "outputId": "59f94548-54f8-4840-e105-f1d1722919b3"
   },
   "outputs": [],
   "source": [
    "sns.lineplot(data=experiment_scores, x=\"threshold\", y=\"score\", hue=\"score_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7jbA8D8j7Nk"
   },
   "source": [
    "Cómo podemos observar, en valores cercanos a 3.5 se alcanza el máximo de las métricas exploradas. Veamos también que reducción en el vocabulario supone el filtrado por peso de idf con distintos límites. Es decir, el tamaño del vocabulario resultante tras limitarlo en función de los distintos valores de `idf`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 524
    },
    "id": "gCIyaUAezi5n",
    "outputId": "a55db072-0ccc-419f-a925-47a4852de687"
   },
   "outputs": [],
   "source": [
    "vocab_sizes = pd.DataFrame(vocab_sizes)\n",
    "ax = sns.lineplot(data=vocab_sizes, x=\"threshold\", y=\"vocab_size\")\n",
    "ax.set(ylim=(2_000,6_000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FlJHbI343ek"
   },
   "source": [
    "### Restricción de valores altos de idf\n",
    "\n",
    "Ya hemos observado el impacto de aplicar el pesado `idf` para encontrar las palabras más relevantes a través de la penaliación o eliminación de valores bajos. A continuación veremos si ocurre algo similar al hacer un filtrado de los valores más altos, dado que en ocasiones, en los valores más altos es común encontrar algunos tokens o dígitos que a priori no deberían aportar (debidos principalmente a impurezas en el dataset). En todo caso, no debería ser un recorde demasiado grande si los textos tienen cierto nivel de limpieza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b21aBDjs45b6",
    "outputId": "14237882-f8aa-429a-8c22-8a09276e3c74"
   },
   "outputs": [],
   "source": [
    "vocab_sizes = []\n",
    "experiment_scores = []\n",
    "for threshold in np.arange(7.5,5,-0.5).tolist():\n",
    "    vocabulary = [word for word, idf_value in idf_values.items() if 3.5 < idf_value < threshold]\n",
    "    print(f\"\\n Threshold: {threshold}, vocab size {len(vocabulary)} \\n\", \"-\"*10)\n",
    "    vocab_sizes.append(\n",
    "        {\n",
    "            'threshold': threshold,\n",
    "            'vocab_size': len(vocabulary)\n",
    "        }\n",
    "    )\n",
    "    tf_idf_vectorizer = TfidfVectorizer(\n",
    "        max_df=MAX_DF,\n",
    "        min_df=MIN_DF,\n",
    "        vocabulary=vocabulary,\n",
    "        #norm=None,\n",
    "        use_idf=True, #if False => tf_vectorize\n",
    "        smooth_idf=1\n",
    "    )\n",
    "    X_tfidf = tf_idf_vectorizer.fit_transform(dataset.data)\n",
    "    scores = quick_eval(kmeans, X_tfidf, threshold=threshold)\n",
    "    experiment_scores += scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ubHNIvXt5HKY"
   },
   "outputs": [],
   "source": [
    "experiment_scores = pd.DataFrame(experiment_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "id": "3m4-k-v65LD8",
    "outputId": "aeb0fc67-fa81-4f7c-86d7-60ce7f21e2be"
   },
   "outputs": [],
   "source": [
    "sns.lineplot(data=experiment_scores, x=\"threshold\", y=\"score\", hue=\"score_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VrzTCUzmlptq"
   },
   "source": [
    "Como podemos observar, salvo para el índice Rand ajustado donde se puede apreciar una mejora marginal al llegar al bajar 7.0, el resto de métricas empeoran tan pronto se reduce el vocabulario.\n",
    "\n",
    "Por tanto, parece que no deberíamos utilizar este filtrado para niveles altos. En todo caso, si ocurriese este fenómeno debido a impurezas en el dataset, la vía para solucionarlo sería la eliminación de las mismas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MzT2m8mH12d3"
   },
   "source": [
    "### Restricción óptima\n",
    "\n",
    "A continuación vamos a ver qué ocurre cuando aplicamos esta restricción cuando se usa cualquiera de las tres funciones de pesado, a través de una restricción de palabras basada en `idf`.\n",
    "\n",
    "Fijaremos el límite en un peso de 3.5, por ser un valor óptimo *como* anteriormente.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r853Xk4p17vC"
   },
   "outputs": [],
   "source": [
    "threshold = 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gb-9hHak2QWG"
   },
   "outputs": [],
   "source": [
    "vocabulary = [word for word, idf_value in idf_values.items() if idf_value > threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4wYN1zQu2pfg"
   },
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(\n",
    "    max_df=MAX_DF,\n",
    "    min_df=MIN_DF,\n",
    "    max_features=MAX_FEATURES,\n",
    "    binary=False,\n",
    "    vocabulary=vocabulary\n",
    ")\n",
    "tf_idf_vectorizer = TfidfVectorizer(\n",
    "    max_df=MAX_DF,\n",
    "    min_df=MIN_DF,\n",
    "    max_features=MAX_FEATURES,\n",
    "    use_idf=True, #if False => tf_vectorize\n",
    "    smooth_idf=1,\n",
    "    vocabulary=vocabulary\n",
    ")\n",
    "binary_vectorizer = CountVectorizer(\n",
    "    max_df=MAX_DF,\n",
    "    min_df=MIN_DF,\n",
    "    max_features=MAX_FEATURES,\n",
    "    binary=True,\n",
    "    vocabulary=vocabulary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XxV86HTn2m7V"
   },
   "outputs": [],
   "source": [
    "vectorizers = {\n",
    "    'tf': tf_vectorizer,\n",
    "    'tf_idf': tf_idf_vectorizer,\n",
    "    'binary': binary_vectorizer\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WmhE0kJv29gt",
    "outputId": "2b70e164-071c-4051-ef4b-739cccd945f7"
   },
   "outputs": [],
   "source": [
    "vectors = {}\n",
    "for vectorizer_name, vectorizer in vectorizers.items():\n",
    "    print(f'fitting {vectorizer_name} vectorizer ...')\n",
    "    vectors[vectorizer_name] = vectorizer.fit_transform(dataset.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJNll1momzVO"
   },
   "source": [
    "Podemos observar que el número de características de cada vectorización es común para todas las funciones de pesado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WlD-StdY3HVf",
    "outputId": "71b1118b-622b-48fd-b824-63e7724b2486"
   },
   "outputs": [],
   "source": [
    "for vectorizer_name, X in vectors.items():\n",
    "    print(f\"{vectorizer_name}: n_samples: {X.shape[0]}, n_features: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0jIcZqjbm8y1"
   },
   "source": [
    "También podemos comprobar como la densidad de valores en las matrices de las vectorizaciones se ha reducido, dado que eliminamos palabras muy presentes en un gran número de documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ATjap4i3KMP",
    "outputId": "85bbb326-f54d-4e8a-c608-84dcbd0a5a9e"
   },
   "outputs": [],
   "source": [
    "for vectorizer_name, X in vectors.items():\n",
    "    print(f\"{vectorizer_name}: {X.nnz / np.prod(X.shape):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tqgXSayHVDoT"
   },
   "source": [
    "Revisemos a continuación los resultados obtenidos en cada caso particular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1t7OR4Gv2hm"
   },
   "source": [
    "#### Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8LtBwn773hlJ",
    "outputId": "42592ed0-0551-4e8e-8037-4e2b067ed491"
   },
   "outputs": [],
   "source": [
    "track_experiment(kmeans, vectors['binary'], name=\"KMeans\\non binary vectors \\nand idf restriction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vaq7UBt0v0dd",
    "outputId": "31f4beaf-2458-44ff-dfac-5ba614a69d06"
   },
   "outputs": [],
   "source": [
    "centroids = kmeans.cluster_centers_\n",
    "get_top_words(centroids, vectorizers['binary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4j2PkUbrVKva"
   },
   "source": [
    "Podemos ver una leve mejora en las métricas respecto a las pruebas iniciales, y cómo en algunas agrupaciones las palabras seleccionadas comienzan a tener más sentido, aunque continuamos encontrando palabras que no guardan una relación clara con el resto de términos. Por ejemplo, para el clúster de religión encontramos:\n",
    "\n",
    "```\n",
    "god believe while must fact before\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eADWsGGZv5Ru"
   },
   "source": [
    "#### TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YMgEmKLz3h1H",
    "outputId": "3f6e74da-3986-4e2d-b221-f71d4f7b770e"
   },
   "outputs": [],
   "source": [
    "track_experiment(kmeans, vectors['tf'], name=\"KMeans\\non tf vectors \\nand idf restriction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M-fOlci4v-3t",
    "outputId": "d46f3f46-6340-4753-df62-e7003409e1ce"
   },
   "outputs": [],
   "source": [
    "centroids = kmeans.cluster_centers_\n",
    "get_top_words(centroids, vectorizers['tf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gx3zz7wrWQ8f"
   },
   "source": [
    "En este caso, encontramos un mayor incremento en las métricas, y agrupaciones que tienen algo más de sentido que con la función de pesado `binary`. Por ejemplo:\n",
    "\n",
    "```\n",
    "lord god christ father unto him son ps jesus said\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kcBqKV-QwBpz"
   },
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sId5pa673ht8",
    "outputId": "06866762-a7c8-467f-ef36-a7addc17ff32"
   },
   "outputs": [],
   "source": [
    "track_experiment(kmeans, vectors['tf_idf'], name=\"KMeans\\non tf-idf vectors \\nand idf restriction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tWDVqQG9wEhR",
    "outputId": "b0b9d971-d6a3-4ab4-e75f-5eac56304bb4"
   },
   "outputs": [],
   "source": [
    "centroids = kmeans.cluster_centers_\n",
    "get_top_words(centroids, vectorizers['tf_idf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLvVbuTfWsUP"
   },
   "source": [
    "Por último, en este caso la mejora ha sido considerable, y la mayoría de las palabras observadas guardan una clara relación entre sí, y definen bien el topic:\n",
    "\n",
    "```\n",
    "god jesus bible believe christian religion him christians belief faith\n",
    "space nasa shuttle moon orbit launch mission earth program\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-HCHiBFvxs-n"
   },
   "source": [
    "#### Comparativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MX6MVMPFwg3S"
   },
   "source": [
    "Como vemos, en los tres casos las palabras más relevantes ya contienen muchas menos stopwords, y vemos que en los casos de tf, y sobre todo de idf, las palabras más relevantes de cada clúster comienzan a tener más relación semántica.\n",
    "\n",
    "Revisemos a continuación las métricas obtenidas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 720
    },
    "id": "wM95SIn5oCUL",
    "outputId": "30274288-7695-430c-bfb4-6a9073d5627e"
   },
   "outputs": [],
   "source": [
    "plot_experiment(evaluations, evaluations_std, size=(8, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YsNKcYifocHT"
   },
   "source": [
    "Como habíamos observado, hay mejora en las métricas. El impacto de esta restricción tiene un gran impacto para el pesado `tf_idf`, mientras que en los otros dos casos el impacto es algo menor (aunque hay mejora), y desigual entre las distintas métricas.\n",
    "\n",
    "Por el momento, es claro que el pesado `idf` tiene un claro impacto en la representación de los textos y cómo podemos condensar la información.\n",
    "\n",
    "A continuación vamos a ver qué ocurre al aplicar LSI para reducir dimensionalidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JgdAQo2-qhIr"
   },
   "source": [
    "## Aplicación de LSI\n",
    "\n",
    "Dado que la reducción aplicada con el pesado `idf` ha tenido un impacto positivo en las métricas, vamos a ver qué ocurre al utilizar SDV para reducir la dimensionalidad, para las tres funciones de pesado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rt8zYGKqxAkd"
   },
   "source": [
    "#### Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EMeyBBKZ6100",
    "outputId": "0642353c-4d7e-41f4-9a7f-deb3e7bea251"
   },
   "outputs": [],
   "source": [
    "lsa = make_pipeline(TruncatedSVD(n_components=100), Normalizer(copy=False))\n",
    "t0 = time()\n",
    "X_lsa = lsa.fit_transform(vectors['binary'])\n",
    "explained_variance = lsa[0].explained_variance_ratio_.sum()\n",
    "\n",
    "print(f\"LSA for binary vectorization done in {time() - t0:.3f} s\")\n",
    "print(f\"Explained variance of the SVD step: {explained_variance * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z-WW5omq68Fu",
    "outputId": "04f67ff9-84eb-4d66-952a-2a44284dd1dd"
   },
   "outputs": [],
   "source": [
    "track_experiment(kmeans, X_lsa, name=\"KMeans\\nwith LSA on binary vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5iAwISkTxLJ9",
    "outputId": "8e2ce0cf-89af-46ca-d398-a0e78bbee759"
   },
   "outputs": [],
   "source": [
    "centroids = lsa[0].inverse_transform(kmeans.cluster_centers_)\n",
    "get_top_words(centroids, vectorizers['binary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMQk0amTYFXj"
   },
   "source": [
    "Tras aplicar la reducción de la dimensionalidad podemos comprobar como en el caso de esta función de pesado existe una gran mejora. Esto apunta a que la eliminación de información no relevante consigue reducir el ruido y mejorar los resultados del algoritmo de agrupamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kdKiZWtdxG0K"
   },
   "source": [
    "#### TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MdppcLxbZoNv",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "6e977b8a-40ff-42ae-b02b-240b961fc166"
   },
   "outputs": [],
   "source": [
    "lsa = make_pipeline(TruncatedSVD(n_components=100), Normalizer(copy=False))\n",
    "t0 = time()\n",
    "X_lsa = lsa.fit_transform(vectors['tf_idf'])\n",
    "explained_variance = lsa[0].explained_variance_ratio_.sum()\n",
    "\n",
    "print(f\"LSA for tf vectorization done in {time() - t0:.3f} s\")\n",
    "print(f\"Explained variance of the SVD step: {explained_variance * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vXUZpKhT6w9m",
    "outputId": "319a2762-12f6-4415-8794-0e71ee3ae2bf"
   },
   "outputs": [],
   "source": [
    "track_experiment(kmeans, X_lsa, name=\"KMeans\\nwith LSA on tf vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NH6nzpvpxTLT",
    "outputId": "af6724e3-621f-433d-aded-48ed372331ee"
   },
   "outputs": [],
   "source": [
    "centroids = lsa[0].inverse_transform(kmeans.cluster_centers_)\n",
    "get_top_words(centroids, vectorizers['tf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f77QiezXZJCu"
   },
   "source": [
    "Al igual que en el caso `binary`, la mejora es importante en este caso también. Veamos qué ocurre en el caso de `tf_idf`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PYlsFapxUP7"
   },
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "85hfOqbR6qlz",
    "outputId": "4a7e74e6-1632-4941-a1f6-7550f543f256"
   },
   "outputs": [],
   "source": [
    "lsa = make_pipeline(TruncatedSVD(n_components=100), Normalizer(copy=False))\n",
    "t0 = time()\n",
    "X_lsa = lsa.fit_transform(vectors['tf'])\n",
    "explained_variance = lsa[0].explained_variance_ratio_.sum()\n",
    "\n",
    "print(f\"LSA for tf-idf vectorization done in {time() - t0:.3f} s\")\n",
    "print(f\"Explained variance of the SVD step: {explained_variance * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6X0Qr5AJZoNv",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "2dbf02ca-a4f4-4671-948d-589b2142ac23"
   },
   "outputs": [],
   "source": [
    "track_experiment(kmeans, X_lsa, name=\"KMeans\\nwith LSA on tf-idf vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s9A6VNVIxins",
    "outputId": "e10cb834-133a-467f-f770-744202e407bc"
   },
   "outputs": [],
   "source": [
    "centroids = lsa[0].inverse_transform(kmeans.cluster_centers_)\n",
    "get_top_words(centroids, vectorizers['tf_idf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "esvmrx9IZgzo"
   },
   "source": [
    "Es interesante ver cómo la varianza explicada en este caso es mucho mayor que en los casos anteriores, y que a pesar de ser buenas, las métricas en este caso se han reducido levemente al aplicar la reducción de dimensionalidad.\n",
    "\n",
    "Esto indica que el efecto del factor de `idf` y la reducción de dimensionalidad tienen un impacto similar, y que la combinación de ambas es parcialente redundante. La reducción de dimensionalidad en este caso ayuda a filtrar mucho del ruido que se provoca en este tipo de representaciones de alta dimensionalidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZG8-SfN_xoV6"
   },
   "source": [
    "#### Comparativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbFyfyjPa9yr"
   },
   "source": [
    "Finalmente vamos a visualizar todos los resultados obtenidos hasta el momento, de manera que podamos tener una comparativa clara de todas las técnicas aplicadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 937
    },
    "id": "QZbAlszdsZdn",
    "outputId": "986b2686-c226-482c-8a28-97e7207a6fd3"
   },
   "outputs": [],
   "source": [
    "plot_experiment(evaluations, evaluations_std, size=(8, 16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJP9Gm91ssPQ"
   },
   "source": [
    "Como podemos ver, que según hemos aplicado refinamientos sobre las técnicas iniciales las métricas no únicamente han mejorado, si no que se han estabilidado y se han igualado los resultados de las distintas funciones de pesado. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SK3XamoHTDX2"
   },
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mSCoC2ydblvQ"
   },
   "source": [
    "En este ejercicio hemos observado el impacto positivo que introduce el pesado basado en la función de idf, que ayuda claramente a ponderar los términos más relevantes.\n",
    "\n",
    "Sin embargo, un filtrado de vocabulario basado en en idf, pero aplicado a funciones de pesado que no incluyen esta técnica no se ha demos trado tan eficaz. Es interesante ver como en los casos de las funciones de pesado `tf` y `binary` podemos igualar lso resultados aplicando una reducción de dimensionalidad basada en LSI.\n",
    "\n",
    "Podemos concluir que con estas funciones de pesado, donde se obtienen representaicones de alta dimensionalidad, es crucial introducir una técnica que ayude a filtrar o ponderar la información más relevante. Apliquemos una u otra, dada la alta presencia de información irrelevante, obtendremos resultados similares, y combinar una con otra no representa una gran mejoría respecto a utilizar únicamente una de ellas, dado que ambas tienen el mismo objetivo."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
